<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="TARS: Training Adaptive Reasoners for Safety.">
    <meta name="keywords" content="TARS, Reasoning for Safety">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Training Adaptive Reasoners for Safety</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <style>
        .main-title {
            font-size: 3rem;
            font-weight: bold;
            color: black;
            margin-bottom: 1rem;
            line-height: 1.2;
            max-width: 100%;
        }
        .paper-title {
            font-size: 2rem;
            color: #5ba0f2;
            margin-bottom: 2rem;
        }
        .blue-button {
            background-color: #87ceeb !important;
            border: 2px solid #000000 !important;
            font-weight: bold !important;
        }
        .blue-button:hover {
            background-color: #6bb6d6 !important;
            border: 2px solid #000000 !important;
        }
        .ingredient-box {
            background-color: white;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            padding: 1.5rem;
            margin-bottom: 1rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .ingredient-label {
            font-weight: bold;
            color: #5ba0f2;
            font-size: 1.2rem;
            margin-bottom: 0.5rem;
        }
        .results-section {
            padding: 3rem 0;
            margin-top: 2rem;
        }
        .results-image {
            width: 100%;
            max-width: 900px;
            margin: 0 auto;
            display: block;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        .section-title {
            font-size: 2rem;
            font-weight: bold;
            color: #5ba0f2;
            margin-bottom: 2rem;
            text-align: center;
        }
        .reasoning-table {
            width: 100%;
            margin: 2rem auto;
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            border-collapse: collapse;
            overflow: hidden;
        }
        .reasoning-table th {
            background-color: #5ba0f2;
            color: white;
            padding: 1rem;
            text-align: left;
            font-weight: bold;
        }
        .reasoning-table td {
            padding: 1rem;
            border-bottom: 1px solid #e9ecef;
        }
        .reasoning-table tr:last-child td {
            border-bottom: none;
        }
        .reasoning-table th:nth-child(2),
        .reasoning-table th:nth-child(3),
        .reasoning-table td:nth-child(2),
        .reasoning-table td:nth-child(3) {
            text-align: center;
        }
        .reasoning-table tr:hover {
            background-color: #f8f9fa;
        }
        .method-section {
            background-color: #f8f9fa;
            padding: 3rem 0;
            margin-top: 2rem;
        }
        .adaptive-section {
            background-color: #f8f9fa;
            padding: 3rem 0;
            margin-top: 2rem;
        }
        .robustness-section {
            /* background-color: #f8f9fa; */
            padding: 3rem 0;
            margin-top: 2rem;
        }
        .robustness-grid {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 1.5rem;
            margin: 2rem 0;
        }
        .robustness-item {
            text-align: center;
        }
        .robustness-item img {
            width: 100%;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            margin-bottom: 0.5rem;
        }
        .robustness-label {
            font-size: 0.9rem;
            font-weight: bold;
            color: #5ba0f2;
            margin-top: 0.5rem;
        }
        .comparison-section {
            background-color: #f8f9fa;
            padding: 3rem 0;
            margin-top: 2rem;
        }
        .comparison-image {
            width: 100%;
            max-width: 800px;
            margin: 2rem auto;
            display: block;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        @media (max-width: 768px) {
            .robustness-grid {
                grid-template-columns: repeat(2, 1fr);
            }
        }
        @media (max-width: 480px) {
            .robustness-grid {
                grid-template-columns: 1fr;
            }
        }
        .author-block {
            margin: 0 1rem;
        }
        .link-item {
            display: inline-block;
            text-align: center;
            margin: 0 0.25rem;
        }
        .coming-soon {
            font-size: 0.75rem;
            color: #6c757d;
            font-style: italic;
            margin-top: 0.25rem;
            line-height: 1;
        }
    </style>
</head>
<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-widescreen">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="main-title">TARS: Training Adaptive Reasoners for Safety</h1>
                        <h2 class="paper-title">Reasoning as an Adaptive Defense for Safety</h2>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://danielkty.github.io">Taeyoun Kim</a></span>
                            <span class="author-block">
                                <a href="https://tajwarfahim.github.io">Fahim Tajwar</a></span>
                            <span class="author-block">
                                <a href="https://www.cs.cmu.edu/~aditirag/">Aditi Raghunathan</a>
                            </span>
                            <span class="author-block">
                                <a href="https://aviralkumar2907.github.io">Aviral Kumar</a>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">Carnegie Mellon University</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-item">
                                    <a href="https://arxiv.org/abs/2507.00971"
                                        target="_blank"
                                       class="external-link button is-normal is-rounded blue-button">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-item">
                                    <a href="https://github.com/danielkty/tars"
                                        target="_blank"
                                       class="external-link button is-normal is-rounded blue-button">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <span class="link-item">
                                    <a href="https://huggingface.co/CMU-AIRe/TARS-1.5B"
                                        target="_blank"
                                       class="external-link button is-normal is-rounded blue-button">
                                        <span class="icon">
                                            <img src="./static/images/huggingface.svg" alt="Hugging Face" style="width: 20px; height: 20px;">
                                        </span>
                                        <span>Model (1.5B)</span>
                                    </a>
                                </span>
                                <span class="link-item">
                                    <a href="https://huggingface.co/CMU-AIRe/TARS-7B"
                                        target="_blank"
                                       class="external-link button is-normal is-rounded blue-button">
                                        <span class="icon">
                                            <img src="./static/images/huggingface.svg" alt="Hugging Face" style="width: 20px; height: 20px;">
                                        </span>
                                        <span>Model (7B)</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Overview</h2>
                    <div class="content has-text-justified">
                        <img src="./static/images/AST Fig.png" alt="TARS Main Figure" style="width: 100%; max-width: 800px; margin: 0 auto; display: block;">
                    </div>
                    <div class="content has-text-justified" style="margin-top: 2rem; margin-bottom: 3rem;">
                        
                        <h3 style="font-size: 1.4rem; font-weight: bold; color: #5ba0f2; margin-bottom: 1rem; margin-top: 2rem;">What is TARS?</h3>
                        <p>
                        TARS is an online RL training recipe that we build to train models that reason for safety. Models trained with TARS exhibit adaptive behaviors by spending more compute on ambiguous queries, leading to better safety-refusal trade-offs. They also internally learn to better distinguish between safe and unsafe prompts and attain greater robustness to both white-box (e.g., GCG) and black-box attacks (e.g., PAIR). Overall, TARS is an effective, open recipe for training LLMs against jailbreaks and harmful requests by reasoning per prompt.
                        </p>
                        
                        <h3 style="font-size: 1.4rem; font-weight: bold; color: #5ba0f2; margin-bottom: 1rem; margin-top: 2rem;">Why do we build TARS?</h3>
                        <p>
                        While reasoning or test-time compute has been shown to improve safety, it remains unclear what the best practices are or what the general recipe is to achieve reasoning models with strong safety and less over-refusal. Key questions include: How should we design the training data? Should we use SFT or RL? What reward functions encourage generalization rather than shortcuts such as refusing to every prompt? To address this, we create an online reinforcement learning recipe with three design choices (ingredients) and train Qwen 2.5 1.5B Instruct into a reasoning model that achieves strong performance on the safety-refusal trade-off. The ablations that led to these design choices are in our <a href="https://arxiv.org/abs/2507.00971" target="_blank" style="color: #5ba0f2;">paper</a>.
                        </p>

                        <h3 style="font-size: 1.4rem; font-weight: bold; color: #5ba0f2; margin-bottom: 1rem; margin-top: 2rem;">Results Overview</h3>
                        <p>
                        TARS has a better safety-refusal trade-off than existing open-weight models and defenses such as circuit breakers. TARS is also more effective than other training methods such as SFT, DPO, and RL without reasoning. <a href="#results" style="color: #5ba0f2;">(Details here)</a>
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Second Section: TARS Recipe -->
    <section class="method-section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="section-title">TARS Recipe</h2>
                    <div class="content has-text-justified" style="margin-bottom: 3rem;">
                        <p>
                            We identify three critical design choices: (1) a ''lightweight'' warmstart SFT stage, (2) a mix of harmful, harmless, and ambiguous prompts to prevent shortcut behaviors such as too many refusals, and (3) a reward function to prevent degeneration of reasoning capabilities during adversarial training. 
                        </p>
                    </div>

                    <div class="content">
                        <div class="ingredient-box">
                            <div class="ingredient-label">Ingredient 1: Lightweight SFT</div>
                            <p>During the SFT warmup stage before online RL training, we found that lightly training with early stopping and a low learning rate increases generation diversity and gives better exploratory behavior during RL. This improves the safety-refusal trade-off after online RL.</p>
                        </div>
                        <div class="ingredient-box">
                            <div class="ingredient-label">Ingredient 2: Mixing Prompts</div>
                            <p>Training on solely harmful prompts with a safety reward during RL leads to degenerate reasoning traces and over-refusal on harmless prompts. Thus, we mix in harmless prompts with a task completion reward to encourage reasoning which carries over to harmful prompts.</p>
                        </div>
                        <div class="ingredient-box">
                            <div class="ingredient-label">Ingredient 3: Reward Design</div>
                            <p>Splitting the reward model into safety and helpfulness rewards increases exploration leading to a wider safety-refusal trade-off.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- <section class="results-section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="section-title" style="margin-bottom: 2rem;">How effective is TARS?</h2>
                    <h3 style="font-size: 1.5rem; font-weight: bold; color: #333; margin-bottom: 1rem;">Safety-Refusal Trade-off</h3>
                    <div class="content has-text-justified">
                        <img src="./static/images/results.png" alt="TARS Results" class="results-image">
                    </div>
                    <div class="content has-text-justified" style="margin-top: 2rem;">
                        <p>
                            We compare TARS-trained models with other training methods: SFT, DPO, and RL without reasoning. For a fair comparison, we train on the same prompts with a similar amount of compute. We evaluate for safety on Harmbench averaged across four attacks (GGC, PAIR, AutoDAN, PAP) and for over-refusal on XSTest. As shown above, models trained with TARS achieve the best safety-refusal trade-off. This means that they defend well against jailbreak attacks and are helpful on harmless prompts without over-refusing. 
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="comparison-section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered">
                <div class="column is-four-fifths">
                    <h3 class="section-title">TARS is safer than open-weight models!</h3>
                    <div class="content has-text-justified">
                        <p>
                          We also compare TARS-trained models against Llama 3.1 8B Instruct, Llama 3.2 1B Instruct, and Circuit Breakers (Llama RR, Mistral RR), which are also 7-8B. For the circuit breakers, we retrain from the base models after removing XSTest from the training data to prevent data contamination.
                        </p>
                        <p>
                          We see that TARS-trained models achieve a better safety-refusal trade-off than Llama models. For circuit breakers, Llama RR is comparable to TARS with a slightly lower performance on the safety-refusal trade-off. Mistral RR, on the other hand, has high refusal rates. We found that Mistral RR learns to output gibberish as an overcautious defense. Furthermore, our comparison highlights that our smaller model (1.5B) can be safer and more helpful than larger models (Llama RR: 8B) when trained to reason with TARS.
                        </p>
                    </div>
                    <img src="./static/images/open-source.png" alt="TARS vs Open-Source Models Safety Comparison" class="comparison-image">
                </div>
            </div>
        </div>
    </section> -->

    <section class="results-section" id="results">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="section-title" style="margin-bottom: 2rem;">How effective is TARS?</h2>
                    
                    <!-- Two plots side by side -->
                    <div class="columns is-centered" style="margin-bottom: 2rem;">
                        <div class="column is-half">
                            <h3 style="font-size: 1.2rem; font-weight: bold; color: #333; margin-bottom: 1rem;">Best Safety-Refusal Trade-off!</h3>
                            <img src="./static/images/results.png" alt="TARS Results" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
                        </div>
                        <div class="column is-half">
                            <h3 style="font-size: 1.2rem; font-weight: bold; color: #333; margin-bottom: 1rem;">Even better than Circuit Breakers!</h3>
                            <img src="./static/images/open-source.png" alt="TARS vs Open-Source Models Safety Comparison" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
                        </div>
                    </div>

                    <!-- Combined description -->
                    <div class="content has-text-justified" style="margin-top: 2rem;">
                        <p>
                            We compare TARS-trained models with other training methods (SFT, DPO, and RL without reasoning) on the safety-refusal trade-off. For a fair comparison, we train on the same prompts with a similar amount of compute. We evaluate for safety on Harmbench averaged across four attacks (GGC, PAIR, AutoDAN, PAP) and for over-refusal on XSTest. As shown above, models trained with TARS achieve the best safety-refusal trade-off. This means that they defend well against jailbreak attacks and are helpful on harmless prompts without over-refusing.
                        </p>
                        <p>
                            We also compare TARS-trained models against Llama 3.1 8B Instruct, Llama 3.2 1B Instruct, and Circuit Breakers (Llama RR, Mistral RR), which are also 7-8B. For circuit breakers, we retrain from the base model after removing XSTest from the training data to prevent data contamination. We see that TARS-trained models achieve a better safety-refusal trade-off than Llama models. For circuit breakers, Llama RR is comparable to TARS with a slightly lower performance on the safety-refusal trade-off. Mistral RR, on the other hand, has high refusal rates. We found that Mistral RR learns to output gibberish as an overcautious defense. Furthermore, our comparison highlights that our smaller model (1.5B) can be safer and more helpful than larger models (Llama RR: 8B) when trained to reason with TARS.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="adaptive-section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered">
                <div class="column is-four-fifths">
                    <h3 class="section-title">Does TARS show adaptive behavior?</h3>
                    <div class="content has-text-justified">
                        <p>
                           TARS also distributes test-time compute across prompts of different complexity. We evaluate our TARS-trained model on Sorry-Bench which categorizes prompts based on their complexity, or how clearly harmful the prompt is. 
                        </p>
                        <p>
                            We observe that reasoning length varies by prompt type, indicating that the model adapts its reasoning based on the nature of the query. For instance, it is shortest for ''Hate Speech Generation'', a clearly harmful category, while it is longest for more ambiguous cases like ''Unqualified Advice''. Looking at generations shown in our <a href="https://arxiv.org/abs/2507.00971" target="_blank" style="color: #5ba0f2;">paper</a>, a hate speech prompt yields a brief 245-token response that quickly references internal knowledge before refusing. In contrast, a prompt asking for advice on removing a driver-assistance system results in a much longer response (593 tokens), reasoning through legal implications, the need for professional intervention, responsibilities of the assistance system, and even accounting for possible user needs such as customization.
                        </p>
                    </div>
                    <table class="reasoning-table">
                        <thead>
                            <tr>
                                <th>Group Topic</th>
                                <th>Reasoning Length</th>
                                <th>Answer Length</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Hate Speech Generation</td>
                                <td>289.88</td>
                                <td>165.18</td>
                            </tr>
                            <tr>
                                <td>Assistance with Crimes or Torts</td>
                                <td>306.01</td>
                                <td>249.07</td>
                            </tr>
                            <tr>
                                <td>Potentially Inappropriate Topics</td>
                                <td>371.67</td>
                                <td>316.39</td>
                            </tr>
                            <tr>
                                <td>Potentially Unqualified Advice</td>
                                <td>456.66</td>
                                <td>608.88</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </div>
    </section>

    <section class="robustness-section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered">
                <div class="column is-four-fifths">
                    <h3 class="section-title">Why is TARS effective?</h3>
                    <div class="content has-text-justified">
                        <p>
                            To understand why TARS achieves a strong safety-refusal trade-off, distinct from SFT, DPO, or standard RL, we examine how models internally represent harmful and harmless prompts. Prior work shows that internal separation of these prompts correlates with safety behavior. We investigate whether similar distinctions emerge in TARS between harmless ''ambiguous'' prompts and attack prompts. We extract 2D UMAP projections of final-layer embeddings on XSTest ''safe'' prompts and GCG attack prompts. To quantify separation, we fit a soft-margin SVM (C=0.1).
                        </p>
                        <p>
                            As shown above, TARS yields the largest margin between harmful and ambiguous prompts, suggesting some of its better adaptivity comes from internal representations. While the only difference between TARS and RL is the reasoning, the prompt embeddings prior to the reasoning block show better separation. This indicates that TARS-trained models develop internal representations that help anticipate refusal decisions before generating a full chain-of-thought better than SFT or DPO. We hypothesize that training for more helpful reasoning also strengthens internal representations formed during the prompt as all weights of the model are updated.
                        </p>
                    </div>
                    <div class="robustness-grid">
                        <div class="robustness-item">
                            <img src="./static/images/last_token_umap_reason_layer_28_svm_refusal_vs_safety.png" alt="TARS">
                            <div class="robustness-label">TARS Margin: 2.21</div>
                        </div>
                        <div class="robustness-item">
                            <img src="./static/images/last_token_umap_sft_layer_28_svm_refusal_vs_safety.png" alt="SFT">
                            <div class="robustness-label">SFT Margin: 1.03</div>
                        </div>
                        <div class="robustness-item">
                            <img src="./static/images/last_token_umap_dpo_layer_28_svm_refusal_vs_safety.png" alt="DPO">
                            <div class="robustness-label">DPO Margin: 1.45</div>
                        </div>
                        <div class="robustness-item">
                            <img src="./static/images/last_token_umap_baseline_layer_28_svm_refusal_vs_safety.png" alt="RL">
                            <div class="robustness-label">RL Margin: 0.88</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
    <div class="container is-max-widescreen">
        <div class="columns is-centered">
            <div class="column is-four-fifths">
                <h3 class="section-title">BibTeX</h3>
                <div class="content">
                    <div style="background-color: #f8f9fa; border: 1px solid #e9ecef; border-radius: 8px; padding: 1.5rem; font-family: 'Courier New', monospace; font-size: 0.9rem; overflow-x: auto; position: relative;">
                        <button onclick="copyBibTeX()" style="position: absolute; top: 10px; right: 10px; background-color: #5ba0f2; color: white; border: none; border-radius: 4px; padding: 6px 12px; font-size: 0.8rem; cursor: pointer; font-weight: bold;" onmouseover="this.style.backgroundColor='#4a8bc2'" onmouseout="this.style.backgroundColor='#5ba0f2'">Copy</button>
<pre id="bibtex-content">@article{kim2025reasoning,
  title={Reasoning as an Adaptive Defense for Safety},
  author={Kim, Taeyoun and Tajwar, Fahim and Raghunathan, Aditi and Kumar, Aviral},
  journal={arXiv preprint arXiv:2507.00971},
  year={2025}
}</pre>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<script>
function copyBibTeX() {
    const bibtext = document.getElementById('bibtex-content').textContent;
    navigator.clipboard.writeText(bibtext).then(function() {
        // Change button text temporarily to show success
        const button = event.target;
        const originalText = button.textContent;
        button.textContent = 'Copied!';
        button.style.backgroundColor = '#28a745';
        setTimeout(function() {
            button.textContent = originalText;
            button.style.backgroundColor = '#5ba0f2';
        }, 2000);
    }).catch(function(err) {
        console.error('Failed to copy: ', err);
        alert('Failed to copy to clipboard');
    });
}
</script>

    <footer class="footer" style="background-color: #f8f9fa; padding: 2rem 0; margin-top: 3rem; border-top: 1px solid #e9ecef;">
        <div class="container">
            <div class="content has-text-centered">
                <p style="color: #6c757d; font-size: 0.9rem;">
                    Website template adapted from <a href="https://nerfies.github.io" style="color: #5ba0f2;">here</a>
                </p>
            </div>
        </div>
    </footer>

</body>
</html>