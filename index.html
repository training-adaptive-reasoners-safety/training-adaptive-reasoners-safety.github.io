<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="TARS: Training Adaptive Reasoners for Safety.">
    <meta name="keywords" content="TARS, Reasoning for Safety">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Training Adaptive Reasoners for Safety</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <style>
        .main-title {
            font-size: 3rem;
            font-weight: bold;
            color: black;
            margin-bottom: 1rem;
            line-height: 1.2;
            max-width: 100%;
        }
        .paper-title {
            font-size: 2rem;
            color: #5ba0f2;
            margin-bottom: 2rem;
        }
        .blue-button {
            background-color: #87ceeb !important;
            border: 2px solid #000000 !important;
            font-weight: bold !important;
        }
        .blue-button:hover {
            background-color: #6bb6d6 !important;
            border: 2px solid #000000 !important;
        }
        .ingredient-box {
            background-color: white;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            padding: 1.5rem;
            margin-bottom: 1rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .ingredient-label {
            font-weight: bold;
            color: #5ba0f2;
            font-size: 1.2rem;
            margin-bottom: 0.5rem;
        }
        .results-section {
            background-color: #f8f9fa;
            padding: 3rem 0;
            margin-top: 2rem;
        }
        .results-image {
            width: 100%;
            max-width: 900px;
            margin: 0 auto;
            display: block;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        .section-title {
            font-size: 2rem;
            font-weight: bold;
            color: #5ba0f2;
            margin-bottom: 2rem;
            text-align: center;
        }
        .reasoning-table {
            width: 100%;
            margin: 2rem auto;
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            border-collapse: collapse;
            overflow: hidden;
        }
        .reasoning-table th {
            background-color: #5ba0f2;
            color: white;
            padding: 1rem;
            text-align: left;
            font-weight: bold;
        }
        .reasoning-table td {
            padding: 1rem;
            border-bottom: 1px solid #e9ecef;
        }
        .reasoning-table tr:last-child td {
            border-bottom: none;
        }
        .reasoning-table tr:hover {
            background-color: #f8f9fa;
        }
        .method-section {
            background-color: #f8f9fa;
            padding: 3rem 0;
            margin-top: 2rem;
        }
        .adaptive-section {
            padding: 3rem 0;
            margin-top: 2rem;
        }
        .robustness-section {
            background-color: #f8f9fa;
            padding: 3rem 0;
            margin-top: 2rem;
        }
        .robustness-grid {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 1.5rem;
            margin: 2rem 0;
        }
        .robustness-item {
            text-align: center;
        }
        .robustness-item img {
            width: 100%;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            margin-bottom: 0.5rem;
        }
        .robustness-label {
            font-size: 0.9rem;
            font-weight: bold;
            color: #5ba0f2;
            margin-top: 0.5rem;
        }
        .comparison-section {
            padding: 3rem 0;
            margin-top: 2rem;
        }
        .comparison-image {
            width: 100%;
            max-width: 800px;
            margin: 2rem auto;
            display: block;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        @media (max-width: 768px) {
            .robustness-grid {
                grid-template-columns: repeat(2, 1fr);
            }
        }
        @media (max-width: 480px) {
            .robustness-grid {
                grid-template-columns: 1fr;
            }
        }
        .author-block {
            margin: 0 1rem;
        }
    </style>
</head>
<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-widescreen">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="main-title">TARS: Training Adaptive Reasoners for Safety</h1>
                        <h2 class="paper-title">Reasoning as an Adaptive Defense for Safety</h2>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://danielkty.github.io">Taeyoun Kim</a></span>
                            <span class="author-block">
                                <a href="https://tajwarfahim.github.io">Fahim Tajwar</a></span>
                            <span class="author-block">
                                <a href="https://www.cs.cmu.edu/~aditirag/">Aditi Raghunathan</a>
                            </span>
                            <span class="author-block">
                                <a href="https://aviralkumar2907.github.io">Aviral Kumar</a>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">Carnegie Mellon University</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="#"
                                       class="external-link button is-normal is-rounded blue-button">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="#"
                                       class="external-link button is-normal is-rounded blue-button">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="#"
                                       class="external-link button is-normal is-rounded blue-button">
                                        <span class="icon">
                                            ðŸ¤—
                                        </span>
                                        <span>Model</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">TARS</h2>
                    <div class="content has-text-justified">
                        <img src="./static/images/AST Fig.pdf" alt="TARS Main Figure" style="width: 100%; max-width: 800px; margin: 0 auto; display: block;">
                    </div>
                    <div class="content has-text-justified" style="margin-top: 2rem;">
                        <p>
                            Reasoning methods that adaptively allocate test-time compute have advanced LLM performance in math and code. In this work, we study how we can utilize this framework to train models that are robust to safety vulnerabilities. We build a recipe called TARS: Training Adaptive Reasoners for Safety, a reinforcement learning (RL) approach that trains models to reason about safety using chain-of-thought traces and a reward signal that balances safety with task completion. When building TARS, we identify three critical design choices: (1) a premature SFT training stage, (2) a mix of harmful, harmless, and ambiguous prompts to prevent shortcut behaviors such as over-refusal, and (3) a reward function to prevent lack of reasoning. Models trained with TARS exhibit adaptive behaviors and spend more compute on ambiguous queries, achieve better safety-refusal trade-offs, internally learn to better distinguish between safe and unsafe prompts, and attain greater robustness to both white-box (e.g., GCG) and black-box attacks (e.g., PAIR). We find that TARS also preserves general reasoning capabilities (e.g., on math benchmarks) despite minimal exposure on such data. Overall, our work provides a principled and open recipe to help LLMs defend against jailbreaks and harmful requests through adaptive reasoning.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="method-section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="section-title">Motivation</h2>
                    <div class="content has-text-justified" style="margin-bottom: 3rem;">
                        <p>
                        While reasoning or test-time compute has been shown to improve safety, it remains unclear what the best practices are or what the general recipe is to achieve reasoning models with strong safety and less over-refusal. Key questions include: How should we design the training data? Should we use SFT or RL? What reward functions encourage generalization rather than shortcuts such as refusing to every prompt? To address this, we create an online reinforcement learning recipe with three design choices (ingredients) that achieve strong performance on the safety-refusal trade-off. Our ablations that led to these design choices are in our <a href="#" style="color: #5ba0f2;">paper</a>.
                        </p>
                    </div>

                    <div class="content">
                        <div class="ingredient-box">
                            <div class="ingredient-label">Ingredient 1: Premature Training</div>
                            <p>During the SFT warmup stage before online RL training, we found that incompletely training with early stopping and a low learning rate gives better exploratory behavior during RL. This increases the safety-refusal trade-off after online RL.</p>
                        </div>
                        <div class="ingredient-box">
                            <div class="ingredient-label">Ingredient 2: Mix Prompts</div>
                            <p>Training on solely harmful prompts with a safety reward during RL leads to degenerate reasoning traces and over-refusal on harmless prompts. Thus, we mix in harmless prompts with a task completion reward to encourage reasoning which carries over to harmful prompts.</p>
                        </div>
                        <div class="ingredient-box">
                            <div class="ingredient-label">Ingredient 3: Split Rewards</div>
                            <p>Splitting the reward model into safety and helpfulness rewards increases exploration and a wider safety-refusal trade-off, leading to increased safety.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="results-section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="section-title" style="margin-bottom: 2rem;">How Effective is TARS?</h2>
                    <h3 style="font-size: 1.5rem; font-weight: bold; color: #333; margin-bottom: 1rem;">Safety-Refusal Trade-off</h3>
                    <div class="content has-text-justified">
                        <img src="./static/images/results.png" alt="TARS Results" class="results-image">
                    </div>
                    <div class="content has-text-justified" style="margin-top: 2rem;">
                        <p>
                            We compare TARS-trained models with other training methods: SFT, DPO, and RL without reasoning. For a fair comparison, we train on the same prompts with a similar amount of compute. We evaluate for safety on Harmbench averaged across four attacks (GGC, PAIR, AutoDAN, PAP) and for over-refusal on XSTest. As shown above, models trained with TARS achieve the best safety-refusal trade-off. This means that they defend well against jailbreak attacks and are helpful on harmless prompts without over-refusing. 
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="adaptive-section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered">
                <div class="column is-four-fifths">
                    <h3 class="section-title">Does TARS show adaptive behavior?</h3>
                    <div class="content has-text-justified">
                        <p>
                           TARS also distributes test-time compute across prompts of different complexity. We evaluate our TARS-trained model on Sorry-Bench which categorizes prompts based on their complexity, or how clearly harmful the prompt is. 
                        </p>
                        <p>
                            We observe that reasoning length varies by prompt type, indicating that the model adapts its reasoning based on the nature of the query. For instance, it is shortest for ``Hate Speech Generation'', a clearly harmful category, while it is longest for more ambiguous cases like ``Unqualified Advice''. Looking at generations shown in <a href="#" style="color: #5ba0f2;">paper</a>, a hate speech prompt yields a brief 245-token response that quickly references internal knowledge before refusing. In contrast, a prompt asking for advice on removing a driver-assistance system results in a much longer response (593 tokens), reasoning through legal implications, the need for professional intervention, responsibilities of the assistance system, and even accounting for possible user needs such as customization.
                        </p>
                    </div>
                    <table class="reasoning-table">
                        <thead>
                            <tr>
                                <th>Group Topic</th>
                                <th>Reasoning</th>
                                <th>Answer</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Hate Speech Generation</td>
                                <td>289.88</td>
                                <td>165.18</td>
                            </tr>
                            <tr>
                                <td>Assistance with Crimes or Torts</td>
                                <td>306.01</td>
                                <td>249.07</td>
                            </tr>
                            <tr>
                                <td>Potentially Inappropriate Topics</td>
                                <td>371.67</td>
                                <td>316.39</td>
                            </tr>
                            <tr>
                                <td>Potentially Unqualified Advice</td>
                                <td>456.66</td>
                                <td>608.88</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </div>
    </section>

    <section class="robustness-section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered">
                <div class="column is-four-fifths">
                    <h3 class="section-title">Why is TARS effective?</h3>
                    <div class="content has-text-justified">
                        <p>
                            Our comprehensive evaluation shows that TARS achieves superior robustness against both white-box attacks (such as Greedy Coordinate Gradient) and black-box attacks (like PAIR). The model maintains strong performance across various attack scenarios while preserving its helpful capabilities on benign requests.
                        </p>
                        <p>
                            The results demonstrate that reasoning-based defenses can provide a more principled approach to AI safety compared to traditional methods. The chart below illustrates the robustness analysis across different attack vectors and safety metrics.
                        </p>
                    </div>
                    <div class="robustness-grid">
                        <div class="robustness-item">
                            <img src="./static/images/last_token_umap_reason_layer_28_svm_refusal_vs_safety.pdf" alt="TARS">
                            <div class="robustness-label">TARS Margin: 2.04</div>
                        </div>
                        <div class="robustness-item">
                            <img src="./static/images/last_token_umap_sft_layer_28_svm_refusal_vs_safety.pdf" alt="SFT">
                            <div class="robustness-label">SFT Margin: 1.03</div>
                        </div>
                        <div class="robustness-item">
                            <img src="./static/images/last_token_umap_dpo_layer_28_svm_refusal_vs_safety.pdf" alt="DPO">
                            <div class="robustness-label">DPO Margin: 1.54</div>
                        </div>
                        <div class="robustness-item">
                            <img src="./static/images/last_token_umap_baseline_layer_28_svm_refusal_vs_safety.pdf" alt="RL">
                            <div class="robustness-label">RL Margin: 0.88</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="comparison-section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered">
                <div class="column is-four-fifths">
                    <h3 class="section-title">TARS is safer than open-source models!</h3>
                    <div class="content has-text-justified">
                        <p>
                            When compared to popular open-source language models, TARS demonstrates significantly improved safety performance across multiple evaluation metrics. Our extensive benchmarking against widely-used models shows that TARS maintains superior resistance to harmful requests while preserving helpfulness on legitimate queries.
                        </p>
                        <p>
                            The comparison reveals that traditional open-source models, while powerful in their capabilities, often lack the sophisticated reasoning mechanisms necessary to handle complex safety scenarios. TARS's adaptive reasoning framework enables it to outperform these models by dynamically adjusting its computational allocation based on the safety implications of each request.
                        </p>
                        <p>
                            This safety advantage is particularly pronounced in scenarios involving ambiguous prompts or sophisticated attack vectors, where TARS's reasoning-based approach provides a robust defense mechanism that goes beyond simple pattern matching or rule-based filtering employed by conventional models.
                        </p>
                    </div>
                    <img src="./static/images/open-source.png" alt="TARS vs Open-Source Models Safety Comparison" class="comparison-image">
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered">
                <div class="column is-four-fifths">
                    <h3 class="section-title">BibTeX</h3>
                    <div class="content">
                        <div style="background-color: #f8f9fa; border: 1px solid #e9ecef; border-radius: 8px; padding: 1.5rem; font-family: 'Courier New', monospace; font-size: 0.9rem; overflow-x: auto;">
<pre>@article{,
  title={},
  author={},
  journal={},
  year={},
}</pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <footer class="footer" style="background-color: #f8f9fa; padding: 2rem 0; margin-top: 3rem; border-top: 1px solid #e9ecef;">
        <div class="container">
            <div class="content has-text-centered">
                <p style="color: #6c757d; font-size: 0.9rem;">
                    Website template adapted from <a href="https://nerfies.github.io" style="color: #5ba0f2;">here</a>
                </p>
            </div>
        </div>
    </footer>

</body>
</html>